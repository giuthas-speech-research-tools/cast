##
## Copyright (c) 2022-2024 Pertti Palo.
##
## This file is part of Computer Assisted Segmentation Tools 
## (see https://github.com/giuthas-speech-research-tools/cast/).
##
## This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.
##
## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License
## along with this program. If not, see <http://www.gnu.org/licenses/>.
##
## The example data packaged with this program is licensed under the
## Creative Commons Attribution-NonCommercial-ShareAlike 4.0
## International (CC BY-NC-SA 4.0) License. You should have received a
## copy of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0
## International (CC BY-NC-SA 4.0) License along with the data. If not,
## see <https://creativecommons.org/licenses/by-nc-sa/4.0/> for details.
##
## When using the toolkit for scientific publications, please cite the
## articles listed in README.markdown. They can also be found in
## citations.bib in BibTeX format.
##

# Structure of this file matters, but order does not.
# id: some id
# name: some name
#
# and
# name: some name
# id: some id
#
# produce the same result.
# person:
#   name: some name
#
# and 
# 
#   name: some name
# person:
# do not.

# This tells CAST which metadata importer to use.
data source: RASL

# Speaker id is used in the output csv file.
speaker id: 20200307145804 04581420200307
# This is where we read the wavs and metadata from.
data directory: eager/3rd_Graders/20200307145804 04581420200307/
# This will be used as the name of the output wav and TextGrid.
outputfilename: eager/3rd_Graders/20200307145804 04581420200307/20200307145804 04581420200307 concatenated_recordings

flags:
  detect beep: False # Should onset beep detection be run?
  utterance: False # Add Utterance Tier.
  file: True # Add File Tier.
  only words: True # Add only Utterance and Word Tiers.
  test: False # Run on only the first 10 recordings.

# Strict YAML file specifying recordings to be excluded based 
# on both prompts and file names.
exclusion list: 

# Consists of words followed by their segments in arbitrary transcription. 
# When only words is True this can be omitted.
pronunciation dictionary: local_data/GFTA_phonemes_in_words_in_SAMPA.csv

# Start and end points of the guess where the word or speech might 
# be in normalised time. If beep detection is used the normalised
# period runs from end of beep to end of recording.
word guess:
  begin: 0.33
  end: 0.5
